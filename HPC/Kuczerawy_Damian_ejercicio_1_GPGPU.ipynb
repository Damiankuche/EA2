{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kuczerawy_Damian_ejercicio_1_GPGPU.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IMR8yqOCOIW"
      },
      "source": [
        "---\n",
        "# 1 Introducción\n",
        "\n",
        "El siguiente cuaderno realiza el binomio de Newton[1] entre los componentes de dos vectores. El ejercicio se resuelve usando CPU-GPU para ver los tiempos de respuesta de cada tipo de ejecución.\n",
        "\n",
        "El binomio de Newton esta dado por la formnula:\n",
        "\n",
        " <center> $(a+b)^n$ </center>\n",
        "\n",
        "**Donde:**\n",
        "\n",
        "$a$ y $b$ son cada uno de los componentes de los vectores.\n",
        "\n",
        "$n$ es el parámetro potencia que solicita el código.\n",
        "\n",
        "Este cuaderno resuelvo hasta el binomio de potencia 4.\n",
        "\n",
        "Tipos de binomio:\n",
        "\n",
        "Potencia: 0\n",
        "\n",
        "$(a+b)^0 = 1$\n",
        "\n",
        "Potencia: 1\n",
        "\n",
        "$(a+b)^1 = a+b$\n",
        "\n",
        "Potencia: 2\n",
        "\n",
        "$(a+b)^2 = a^2+2a*b+b^2$\n",
        "\n",
        "Potencia: 3\n",
        "\n",
        "$(a+b)^3 = a^3+3a^2*b+3a*b^2+b^3$\n",
        "\n",
        "Potencia: 4\n",
        "\n",
        "$(a+b)^4 = a^4+4a^3*b+6a^2*b^2+4a*b^3+b^4$\n",
        "\n",
        "\n",
        "Estos ejercicios están resueltos en lenguaje Python[2] en la plataforma Colab[3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F045JtRUCXhI"
      },
      "source": [
        "---\n",
        "# 2 Armado del ambiente\n",
        "Instala en el cuaderno el módulo CUDA de Python para el correcto funcionamiento del item 3.2 donde el codigo se ejecuta en CPU-GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te47Ur-zCY7b"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-zaDFIMCdxH"
      },
      "source": [
        "---\n",
        "# 3 Desarrollo\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYW9n1tLCepW"
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title 3.1 Parámetros de ejecución de CPU-GPU { vertical-output: true }\n",
        "\n",
        "class ParametroException(Exception):\n",
        "  #Ocurre cuando los parametros ingresados son incorrectos.\n",
        "  def __init__(self,*args,**kwargs):\n",
        "    Exception.__init__(self,*args,**kwargs)\n",
        "\n",
        "try:\n",
        "  cantidad =   300#@param {type: \"number\"}\n",
        "  potencia =   3#@param {type: \"number\"}\n",
        "\n",
        "  # --------------------------------------------\n",
        "  if potencia < 0 or potencia > 4 or type(potencia) != type(1):\n",
        "    raise TypeError\n",
        "  if cantidad < 0:\n",
        "    raise TypeError\n",
        "\n",
        "  from datetime import datetime\n",
        "\n",
        "  tiempo_total = datetime.now()\n",
        "  try:\n",
        "    import sys\n",
        "    import pycuda.driver as cuda\n",
        "    import pycuda.autoinit\n",
        "    from pycuda.compiler import SourceModule\n",
        "  except:\n",
        "    print(\"No se ejecutó el Item 2 - Armado de ambiente.\")\n",
        "    raise NameError(\"Item 2 no ejecutado\")\n",
        "\n",
        "  import numpy\n",
        "\n",
        "  # --------------------------------------------\n",
        "  # Definición de función que transforma el tiempo en  milisegundos \n",
        "  tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "\n",
        "  x_cpu = numpy.random.randn(cantidad)\n",
        "  x_cpu = x_cpu.astype(numpy.float32())\n",
        "\n",
        "  y_cpu = numpy.random.randn(cantidad)\n",
        "  y_cpu = y_cpu.astype(numpy.float32()) \n",
        "\n",
        "  res_cpu = numpy.empty_like (x_cpu)\n",
        "\n",
        "  #CPU - reservo la memoria GPU\n",
        "  x_gpu = cuda.mem_alloc(x_cpu.nbytes)\n",
        "  y_gpu = cuda.mem_alloc(y_cpu.nbytes)\n",
        "\n",
        "  #GPU - Copio la memoria al GPU\n",
        "  cuda.memcpy_htod(x_gpu, x_cpu)\n",
        "  cuda.memcpy_htod(y_gpu, y_cpu)\n",
        "\n",
        "\n",
        "  #CPU - Defino la función kernel que se ejecutará en GPU.\n",
        "  module = SourceModule(\"\"\"\n",
        "\n",
        "  __global__ void kernel_binomio(int n,int pot, float *X , float *Y)\n",
        "  {\n",
        "      int idx = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "      if( idx < n){\n",
        "\n",
        "        switch(pot)\n",
        "        {\n",
        "            case 0:\n",
        "              Y[idx] = 1;\n",
        "            break;\n",
        "            case 1:\n",
        "              Y[idx] = X[idx] + Y[idx];\n",
        "            break;\n",
        "            case 2:\n",
        "              Y[idx] = pow(X[idx],2) + 2*X[idx]*Y[idx]+pow(Y[idx],2);\n",
        "            break;\n",
        "            case 3:\n",
        "              Y[idx] = pow(X[idx],3) + 3*pow(X[idx],2)*Y[idx]+3*X[idx]*pow(Y[idx],2)+pow(Y[idx],3);\n",
        "            break;\n",
        "            case 4:\n",
        "              Y[idx] = pow(X[idx],4) + 4*pow(X[idx],3)*Y[idx]+6*pow(X[idx],2)*pow(Y[idx],2)+ 4*X[idx]*pow(Y[idx],3)+pow(Y[idx],4);\n",
        "            break;\n",
        "        }\n",
        "      }   \n",
        "  }\n",
        "  \"\"\")\n",
        "  #CPU - genero la función kernel\n",
        "  kernel = module.get_function(\"kernel_binomio\")\n",
        "\n",
        "  tiempo_gpu = datetime.now()\n",
        "\n",
        "  # GPU - Ejecuta el kernel.\n",
        "  dim_hilo = 256\n",
        "  dim_bloque = numpy.int( (cantidad+dim_hilo-1) / dim_hilo )\n",
        "\n",
        "  kernel( numpy.int32(cantidad),numpy.int32(potencia), x_gpu, y_gpu, block=( dim_hilo, 1, 1 ),grid=(dim_bloque, 1,1) )\n",
        "\n",
        "  tiempo_gpu = datetime.now() - tiempo_gpu\n",
        "\n",
        "\n",
        "  # GPU - Copio el resultado desde la memoria GPU.\n",
        "  cuda.memcpy_dtoh(res_cpu, y_gpu)\n",
        "\n",
        "  \"\"\"\n",
        "  # CPU - Informo el resutlado.\n",
        "  print( \"------------------------------------\")\n",
        "  print( \"X: \" )\n",
        "  print( x_cpu )\n",
        "  print( \"------------------------------------\")\n",
        "  print( \"Y: \" )\n",
        "  print( y_cpu )\n",
        "  print( \"------------------------------------\")\n",
        "  print( \"Resultado: \" )\n",
        "  print( res_cpu )\n",
        "  \"\"\"\n",
        "\n",
        "  tiempo_total = datetime.now() - tiempo_total\n",
        "\n",
        "  print( \"Cantidad de elementos: \", cantidad)\n",
        "  print( \"Thread x: \", dim_hilo, \", Bloque x:\", dim_bloque )\n",
        "  print(\"Tiempo CPU: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n",
        "  print(\"Tiempo GPU: \", tiempo_en_ms( tiempo_gpu   ), \"[ms]\" )\n",
        "\n",
        "except TypeError as err:\n",
        "  print(\"Los parametros ingresados son incorrectos.\")\n",
        "  print(\"Cantidad debe ser un numero entero positivo.\")\n",
        "  print(\"Potencia debe ser un numero entero comprendido entre 0 y 4.\")\n",
        "  print(err)\n",
        "except NameError as err:\n",
        "  print(err)\n",
        "except Exception as err:\n",
        "  print(\"Ocurrió un error inesperado.\")\n",
        "  print(type(err))\n",
        "  print(err)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCv77dTWCtRm"
      },
      "source": [
        "---\n",
        "#4 Tabla de pasos\n",
        "Tabla de pasos de la ejecución del programa CPU-GPU:\n",
        "\n",
        " Procesador | Funciòn | Detalle\n",
        "------------|---------|----------\n",
        "CPU      |  Custom Exception                | Se crea una excepcion customizada\n",
        "CPU      |  @param                | Lectura del tamaño de vectores desde Colab.\n",
        "CPU      |  validación                | Se validan los parametros ingresados.\n",
        "CPU      |  import                | Importa los módulos para funcionar.\n",
        "CPU      |  datetime.now()        | Toma el tiempo actual.\n",
        "CPU      |  numpy.random.randn( Cantidad ) | Inicializa los vectores X, Y y Res.\n",
        "**GPU**  |  cuda.mem_alloc()      | Reserva la memoria en GPU.\n",
        "**GPU**  |  cuda.memcpy_htod()    | Copia las memorias desde el CPU al GPU.\n",
        "CPU      |  SourceModule()        | Define el código del kernel \n",
        "CPU      |  module.get_function() | Genera la función del kernel GPU\n",
        "CPU      |  dim_tx/dim_bx         | Calcula las dimensiones.\n",
        "**GPU**  |  kernel()              | Ejecuta el kernel en GPU\n",
        "CPU      |  cuda.memcpy_dtoh( )   | Copia el resultado desde GPU a CPU vector Res.\n",
        "CPU      |  print()               | Informo los resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WrxPLGMKPLk"
      },
      "source": [
        "---\n",
        "# 5 Conclusiones\n",
        "\n",
        "Como se puede ver en las ejecuciones, para poco cálculo la ejecución secuencial en CPU es más rápida ya que la ejecución CPU-GPU tiene que hacer la reserva de memoria en el GPU, copiar los datos a trabajar y despues copiar otra vez los resultados al vector correspondiente, por lo que se traduce en un overhead enorme y por los pocos datos a procesar no tiene sentido.\n",
        "\n",
        "Pero si la carga de datos a procesar es muy grande la diferencia entre trabajar secuencialmente con trabajar con los threads del GPU de forma paralela es muy amplia y ahí si tiene sentido y da una respuesta muchisimo más rapida trabajar con el GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw9uu39_KSJ7"
      },
      "source": [
        "---\n",
        "# 6 Bibliografía\n",
        "\n",
        "[1] Binomio de Newtom: [Wiki](https://es.wikipedia.org/wiki/Teorema_del_binomio)\n",
        "\n",
        "[2] Introducción a Python: [Página Colab](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/Python_Basico.ipynb) \n",
        "\n",
        "[3] MARKDOWN SYNTAX Colab: [PDF](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/markdown-cheatsheet-online.pdf)"
      ]
    }
  ]
}